<!DOCTYPE html>
<html lang="en-us">

<head>
    <meta name="generator" content="Hugo 0.104.3" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1">
    <title>Dehong Xu</title>
    <meta property="og:title" content="Dehong Xu">
    <meta property="og:type" content="website">


    <meta property="og:image" content="img/main1.png">

    <meta property="og:url" content="https://dehongxu.github.io/">

    <meta property="og:description" content="The homepage of Dehong Xu">
    <meta name="Description" property="description" content="The homepage of Dehong Xu">



    <link rel="stylesheet" href="css/style.min.css">
    <link rel="icon" href=img/logo_UCLA_blue.svg>
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/svg+xml" href="/favicon.svg">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <meta name="theme-color" content="#ffffff">
    <link rel="webmention" href="https://webmention.io/hugocisneros.com/webmention">
    <link rel="pingback" href="https://webmention.io/hugocisneros.com/xmlrpc">

    <script>function updateMode() { localStorage.theme === "dark" || !("theme" in localStorage) && window.matchMedia("(prefers-color-scheme: dark)").matches ? document.documentElement.classList.add("dark") : document.documentElement.classList.remove("dark") } function toggleMode() { localStorage.theme === "dark" ? localStorage.theme = "light" : localStorage.theme = "dark", updateMode() } window.onload = updateMode(); function toggleMenu() { let e = document.getElementById("navbar-default"); e.classList.contains("hidden") ? e.classList.remove("hidden") : e.classList.add("hidden") }</script>

</head>

<body>
    <header class="md:px-0 px-2">
        <nav>
            <div class="container flex flex-wrap justify-between items-center mx-auto">
                <div class="nav-main my-2.5">
                    <a href="https://dehongxu.github.io/"
                        class="nav-title py-2.5 text-2xl text-zinc-600 dark:text-zinc-300 hover:border-b-0">Dehong
                        Xu</a>
                </div>
                <button type="button" onclick="toggleMenu()" class="inline-flex items-center p-2 ml-3
                              text-sm text-gray-500
                              rounded-lg md:hidden hover:bg-gray-100
                              focus:outline-none focus:ring-2
                              focus:ring-gray-200 dark:text-gray-400
                              dark:hover:bg-gray-700 dark:focus:ring-gray-600" aria-controls="navbar-default"
                    aria-expanded="false">
                    <span class="sr-only">Open main menu</span>
                    <svg class="w-6 h-6" aria-hidden="true" fill="currentColor" viewBox="0 0 20 20"
                        xmlns="http://www.w3.org/2000/svg">
                        <path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1
                                       0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1
                                       0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1
                                       0 01-1-1z" clip-rule="evenodd"></path>
                    </svg>
                </button>
                <div class="hidden w-full md:block md:w-auto" id="navbar-default">
                    <ul class="grid md:grid-flow-col items-center justify-between text-lg my-2.5">
                        <li class="p-2.5 md:first:pl-0 md:border-none border-b list-none">
                            <a class="text-zinc-600 dark:text-zinc-300 hover:border-b-0" href="#about">About</a>
                        </li>
                        <li class="p-2.5 md:first:pl-0 md:border-none border-b list-none">
                            <a class="text-zinc-600 dark:text-zinc-300 hover:border-b-0" href="#research">Research</a>
                        </li>
                        <li class="p-2.5 md:first:pl-0 md:border-none border-b list-none">
                            <a class="text-zinc-600 dark:text-zinc-300 hover:border-b-0"
                                href="#experience">Experience</a>
                        </li>
                        <li class="p-2.5 md:first:pl-0 md:border-none border-b list-none">
                            <a class="text-zinc-600 dark:text-zinc-300 hover:border-b-0" href="#teaching">Teaching</a>
                        </li>
                        <li class="p-2.5 md:first:pl-0 md:border-none border-b list-none">
                            <a class="text-zinc-600 dark:text-zinc-300 hover:border-b-0" href="about/CV.pdf">CV</a>
                        </li>

                        <li class="h-7 pl-2.5 pr-0 list-none">
                            <button type="button" onclick="toggleMode()" class="h-full"
                                aria-label="Toggle between dark and light mode">
                                <img class="h-7 w-7 max-h-full mb-1.5 p-1.5 hidden dark:inline"
                                    id="ligh-mode-button-img" alt="A sun icon for switching to light mode"
                                    src="img/light_mode.svg">
                                <img class="h-7 w-7 max-h-full mb-1.5 p-1.5 inline dark:hidden"
                                    id="dark-mode-button-img" alt="A moon icon for switching to dark mode"
                                    src="img/dark_mode.svg">
                            </button>
                        </li>
                    </ul>
                </div>
            </div>
        </nav>
    </header>

    <main class="content h-card container mt-2 m-auto leading-loose md:px-0 px-2 z-0 Page(/_index.md)" role="main">

        <div class="head container grid sm:grid-cols-2 grid-cols-1
            justify-around flex-wrap items-center" itemscope itemtype="http://schema.org/Person">
            <div class="picture p-4 max-w-[90%] mx-auto basis-20 grow shrink" itemscope
                itemtype="http://schema.org/ImageObject">
                <picture>

                    <source srcset="img/main1.png">
                    <img class="main-image u-photo mx-auto" itemprop="contentUrl" alt="Main picture"
                        src="img/main1.png">
                </picture>
            </div>
            <!-- <div class="mx-4 ml-8 basis-60 grow shrink-2 leading-snug text-base"> -->
            <div class="text-content mx-8 basis-auto grow leading-snug text-base">
                <a class="u-url font-bold" rel="me" itemprop="url" href="https://dehongxu.github.io/">
                    <h1 class="text-black dark:text-zinc-300 p-name border-0" itemprop="name">Dehong Xu
                    </h1>
                </a>
                <section id="about">
                    <h2 itemprop="jobTitle" class="text-xl my-0 border-none">Ph.D. Candidate</h2>

                    <div itemprop="address" itemscope itemtype="http://schema.org/PostalAddress">
                        <span itemprop="addressLocality">Department of Statistics</span>
                        <br>
                        <span itemprop="addressLocality">University of California, Los Angeles</span>
                        <br>
                        Advisor: Prof. <a href="http://www.stat.ucla.edu/~ywu/">Ying Nian Wu</a> and </a><a
                            href="http://www.stat.ucla.edu/~sczhu/">Song-chun Zhu</a>
                        <br>
                        <br>
                        <span itemprop="streetAddress">
                            Email: xudehong1996@ucla.edu
                        </span>
                        <br>
                        <br>
                        <a href="https://scholar.google.com/citations?user=uKEXF54AAAAJ&hl=en&authuser=1">Google
                            Scholar</a> &ensp;
                        <a href="https://www.linkedin.com/in/dehong-xu-61a947248/">LinkedIn</a>
                        &ensp;
                        <a href="https://github.com/DehongXu">GitHub</a>


                        <br>
                    </div>

            </div>
        </div>
        </section>


        <section id="research">
            <h2 id="bio">Bio</h2>
            <p>I am a final-year Ph.D. student in the <a href="https://statistics.ucla.edu/">Department of
                    Statistics</a> at <b>UCLA</b>, advised by Prof. <a href="http://www.stat.ucla.edu/~ywu/">Ying Nian
                    Wu
                </a>and <a href="http://www.stat.ucla.edu/~sczhu/">Song-chun Zhu</a>. I was a member of <a
                    href="https://vcla.stat.ucla.edu/" target="_blank">the Center for Vision, Cognition, Learning, and
                    Autonomy (VCLA)</a>. Previously, I conducted research at
                <b><a href="https://www.amazon.science/">Amazon Rufus team</a></b> and
                <b><a href="https://www.amazon.science/">Amazon AGI team</a></b>.
            </p>
            <p>My research explores the intersections of language modeling, representation learning, and
                decision-making.</p>
            <p>ðŸŒŸ <b>Actively seeking full-time Research Scientist position for 2025.</b> ðŸŒŸ

            <p>Â </p>

            <h2 id="news">News</h2>
            <ul>
                <li>
                    <strong>[02/2025]&nbsp; <font color="red">New!</font></strong>
                    One paper <a href="https://arxiv.org/abs/2502.01567" target="_blank">Scalable Language Models with
                        Posterior Inference of Latent Thought Vectors</a>
                    is available at <b>Preprint</b>!
                </li>
                <li>
                    <strong>[01/2025]&nbsp; <font color="red">New!</font></strong>
                    One paper <a href="https://arxiv.org/abs/2405.16865" target="_blank">An Investigation of Conformal
                        Isometry Hypothesis for Grid Cells</a>, is accepted by <b>ICLR 2025</b> with <i><font color="red">Oral Presentation (1.8%)</font></i>!
                </li>
                <li>
                    <strong>[10/2024]&nbsp; <font color="red">New!</font></strong>
                    One paper on representation modeling for head direction system is accepted by the
                    Workshop on Symmetry and Geometry in Neural Representations (NeurReps) at NeurIPS 2024!
                </li>
                <li>
                    <strong>[09/2024]&nbsp; <font color="red">New!</font></strong>
                    One paper <a href="https://arxiv.org/abs/2402.04647">Latent Plan Transformer</a>, is accepted by
                    <!-- <b><a href="https://nips.cc/Conferences/2024" target="_blank">NeurIPS 2024</a></b>! -->
                    <b>NeurIPS 2024</b>!
                </li>
                <li><strong>[06/2024]&nbsp; <font color="red">New!</font></strong>
                    I will be joining
                    <b><a href="https://www.amazon.science/">Amazon Rufus team</a></b> as a Applied Scientist intern
                    this summer!
                </li>
                <li><strong>[05/2024]&nbsp; <font color="red">New!</font></strong>
                    One paper <a href="https://arxiv.org/abs/2406.02756">Aligning Large Language Models via Fine-grained
                        Supervision</a>, is accepted by
                    <!-- <b><a href="https://2024.aclweb.org/" target="_blank">ACL 2024</a></b>! -->
                    <b>ACL 2024</b>!
                </li>
                <li><strong>[06/2023]&nbsp; </strong>
                    I will be joining <b><a href="https://www.amazon.science/">Amazon AGI team</a></b> as a Applied
                    Scientist intern this summer!
                </li>
                <li><strong>[05/2023]&nbsp; </strong>
                    One paper <a href="https://arxiv.org/abs/2306.01153">Diverse and Faithful Knowledge-Grounded
                        Dialogue Generation via Sequential Posterior Inference</a>, is accepted by
                    <!-- <b><a href="https://icml.cc/Conferences/2023" target="_blank">ICML 2023</a></b>! -->
                    <b>ICML 2023</b>!
                </li>
            </ul>
            <p>Â </p>

            <h2 id="publications">Selected Publications</h2>
            <div>
                * denotes equal contribution.
            </div>



            <!-- <div class="pub-wrapper w-full inline-flex flex-wrap items-center
                my-1.5 p-2.5 rounded bg-slate-100 dark:bg-slate-700 box-border
                leading-tight justify-around" id="a-minimalistic-representation-model-for-head-direction-system"
                itemscope itemtype="http://schema.org/ScholarlyArticle">
                <div class="pub-image basis-40 grow-0 shrink" itemprop="image" itemscope
                    itemtype="http://schema.org/ImageObject">
                    <img alt="Illustration of A minimalistic representation model for head direction system"
                        itemprop="url" src="img/Head-direction.png" class="w-full" />
                </div>
                <div class="publication grow shrink-2 basis-3/4 my-1.5 mx-2">
                    <br>
                    <b>
                        <a href="https://arxiv.org/abs/2411.10596v1">
                            <span itemprop="name">A Minimalistic Representation Model for Head Direction System</span>
                        </a>
                    </b>
                    <meta itemprop="headline" content="A minimalistic representation model for head direction system" />
                    <br>

                    <span itemprop="author" style="color: grey;">Minglu Zhao</span>,

                    <b><span itemprop="author">Dehong Xu</span></b>,

                    <span itemprop="author" style="color: grey;">Wenhao Zhang</span>,

                    <span itemprop="author" style="color: grey;">Ying Nian Wu</span>

                    <div>
                        <b><a href="https://www.neurreps.org/" target="_blank">NeurIPS Workshop on Symmetry and Geometry
                                in Neural Representations</a></b>

                    </div>
                    <div itemprop="description" class="pub-description text-sm my-1.5">We present a model for the head
                        direction (HD) system that captures essential HD cell properties through a high-dimensional U(1)
                        representation. This model reveals Gaussian-like tuning and 2D circular geometry, accurately
                        supporting path integration in both fully connected and convolutional forms. </div>
                    <div class="pub-link-wrapper mt-1.5 text-sm">
                        <span class="publication-link bg-sky-600
                             dark:bg-sky-700 rounded-sm p-1
                             dark:hover:bg-sky-500
                             hover:bg-sky-800 mr-1">
                            <a class="border-none
                             text-white
                             dark:text-zinc-200
                             hover:text-gray-900
                              hover:dark:text-gray-800" itemprop="mainEntityOfPage"
                                href="https://arxiv.org/abs/2411.10596">paper</a>
                        </span>
                        <span class="publication-link cursor-pointer
                             bg-sky-600 dark:bg-sky-700
                             hover:bg-sky-800
                             dark:hover:bg-sky-500
                             text-white
                             dark:text-zinc-200
                             dark:hover:text-gray-800
                             hover:text-gray-900
                             rounded-sm p-1 mr-1">
                            <button class="open-modal text-inherit"
                                data-target="#open-modal-a-minimalistic-representation-model-for-head-direction-system">cite</button>
                        </span>
                    </div>
                </div>
            </div> -->

            <!-- <div id="#open-modal-a-minimalistic-representation-model-for-head-direction-system" class="modal-window bg-tp-black invisible fixed top-0 left-0
                right-0 bottom-0 transition-all pointer-events-none z-50">
                <div class="absolute top-1/2 left-1/2 p-8 bg-white
                    dark:bg-neutral-700
                    max-w-full
                    rounded-md max-w-4/5 -translate-x-1/2 -translate-y-1/2">
                    <button id="#close-modal-a-minimalistic-representation-model-for-head-direction-system"
                        title="Close" class="modal-close rounded-sm p-2">âœ•</button>
                    <h3>Cite <i>A minimalistic representation model for head direction system</i></h3>
                    <button class="modal-copy-citation pr-2 pl-1 my-2 ml-2
                           bg-sky-600 dark:bg-sky-700 rounded-sm
                           text-white
                           dark:text-zinc-200
                           dark:hover:text-gray-800
                           hover:text-gray-900
                           hover:bg-sky-800
                           disabled:bg-neutral-500
                           hover:disabled:text-white
                           dark:hover:disabled:text-zinc-200
                           dark:disabled:bg-neutral-500
                           dark:hover:bg-sky-500" id="#copy-minimalistic-representation-model">Copy to
                        clipboard</button>
                    <pre class="bg-slate-100 dark:bg-slate-800">
                        <code id="minimalistic-representation-model">
@article{zhao2024head,
    title={A minimalistic representation model for head direction system},
    author={Zhao, Minglu and Xu, Dehong and Kong, Deqian and Zhang, Wen-Hao and Wu, Ying Nian},
    journal={NeurIPS 2024 Workshop on Symmetry and Geometry in Neural Representations (NeurReps)},
    year={2024}
}</code>
                    </pre>
                </div>
            </div> -->

            <div class="pub-wrapper w-full inline-flex flex-wrap items-center
                my-1.5 p-2.5 rounded bg-slate-100 dark:bg-slate-700 box-border
                leading-tight justify-around" id="ltm"
                itemscope itemtype="http://schema.org/ScholarlyArticle">
                <div class="pub-image basis-40 grow-0 shrink" itemprop="image" itemscope
                    itemtype="http://schema.org/ImageObject">
                    <img alt="Illustration of An Investigation of Conformal Isometry Hypothesis for Grid Cells"
                        itemprop="url" src="img/LTM-scaling.png" class="w-full" />
                </div>
                <div class="publication grow shrink-2 basis-3/4 my-1.5 mx-2">
                    <br>
                    <b>
                        <a href="https://arxiv.org/abs/2502.01567">
                            <span itemprop="name">Scalable Language Models with Posterior Inference of Latent Thought Vectors</span>
                        </a>
                    </b>
                    <meta itemprop="headline"
                        content="Scalable Language Models with Posterior Inference of Latent Thought Vectors" />
                    <br>

                    <span itemprop="author" style="color: grey;">Deqian Kong*</span>,

                    <span itemprop="author" style="color: grey;">Minglu Zhao*</span>,

                    <b><span itemprop="author">Dehong Xu*</span></b>,

                    <span itemprop="author" style="color: grey;">Bo Pang</span>,

                    <span itemprop="author" style="color: grey;">Shu Wang</span>,

                    <span itemprop="author" style="color: grey;">Edouardo Honig</span>,

                    <span itemprop="author" style="color: grey;">Zhangzhang Si</span>,

                    <span itemprop="author" style="color: grey;">Chuan Li</span>,

                    <span itemprop="author" style="color: grey;">Jianwen Xie<sup>â€ </sup></span>,

                    <span itemprop="author" style="color: grey;">Sirui Xie<sup>â€ </sup></span>,

                    <span itemprop="author" style="color: grey;">Ying Nian Wu<sup>â€ </sup></span>

                    <div>
                        <b>Available at Preprint</b>
                    </div>
                    <div itemprop="description" class="pub-description text-sm my-1.5">
                        We introduce <b>Latent-Thought Language Models (LTMs)</b>, a novel language model family that incorporates 
                        explicit latent thought vectors. LTMs leverage dual-rate optimization, rapidly updating local latent 
                        vectors while gradually refining global decoder parameters. This approach unlocks new scaling dimensions, 
                        achieving superior efficiency, perplexity, and zero-shot performance over traditional models. They also 
                        exhibit emergent few-shot reasoning, highlighting their potential for advanced language tasks.
                    </div>
                    <div class="pub-link-wrapper mt-1.5 text-sm">
                        <span class="publication-link bg-sky-600
                             dark:bg-sky-700 rounded-sm p-1
                             dark:hover:bg-sky-500
                             hover:bg-sky-800 mr-1">
                            <a class="border-none
                             text-white
                             dark:text-zinc-200
                             hover:text-gray-900
                              hover:dark:text-gray-800" itemprop="mainEntityOfPage"
                                href="https://arxiv.org/abs/2502.01567">paper</a>
                        </span>

                        <span class="publication-link cursor-pointer
                             bg-sky-600 dark:bg-sky-700
                             hover:bg-sky-800
                             dark:hover:bg-sky-500
                             text-white
                             dark:text-zinc-200
                             dark:hover:text-gray-800
                             hover:text-gray-900
                             rounded-sm p-1 mr-1">
                            <button class="open-modal text-inherit"
                                data-target="#open-modal-ltm">cite</button>
                        </span>
                    </div>
                </div>
            </div>

            <div class="pub-wrapper w-full inline-flex flex-wrap items-center
                my-1.5 p-2.5 rounded bg-slate-100 dark:bg-slate-700 box-border
                leading-tight justify-around" id="grid-cell"
                itemscope itemtype="http://schema.org/ScholarlyArticle">
                <div class="pub-image basis-40 grow-0 shrink" itemprop="image" itemscope
                    itemtype="http://schema.org/ImageObject">
                    <img alt="Illustration of An Investigation of Conformal Isometry Hypothesis for Grid Cells"
                        itemprop="url" src="img/grid_cell.png" class="w-full" />
                </div>
                <div class="publication grow shrink-2 basis-3/4 my-1.5 mx-2">
                    <br>
                    <b>
                        <a href="https://arxiv.org/abs/2402.04647">
                            <span itemprop="name">An Investigation of Conformal Isometry Hypothesis for Grid Cells</span>
                        </a>
                    </b>
                    <meta itemprop="headline"
                        content="An Investigation of Conformal Isometry Hypothesis for Grid Cells" />
                    <br>

                    <b><span itemprop="author">Dehong Xu</span></b>,

                    <span itemprop="author" style="color: grey;">Ruiqi Gao</span>,

                    <span itemprop="author" style="color: grey;">Wen-Hao Zhang</span>,

                    <span itemprop="author" style="color: grey;">Xue-Xin Wei</span>,

                    <span itemprop="author" style="color: grey;">Ying Nian Wu</span>

                    <div>
                        <b><a href="https://iclr.cc/Conferences/2025" target="_blank">ICLR 2025</a> <font color="red">[Oral Presentation (1.8%)]</font> </b>
                    </div>
                    <div itemprop="description" class="pub-description text-sm my-1.5">
                        This paper explores the conformal isometry hypothesis as a unifying explanation for the hexagonal 
                        firing patterns of grid cells. It posits that an animalâ€™s 2D location is encoded as a high-dimensional 
                        neural vector lying on a 2D manifold, where local distances in physical space are preserved up to a 
                        scaling factor. We are the first paper to provide theortical proof that conformal isometry leads to the 
                        emergence of grid cell hexagonality. And we further conduct numerical experiments that such local 
                        distance preservation naturally produces the observed hexagonal grid. 
                    </div>
                    <div class="pub-link-wrapper mt-1.5 text-sm">
                        <span class="publication-link bg-sky-600
                             dark:bg-sky-700 rounded-sm p-1
                             dark:hover:bg-sky-500
                             hover:bg-sky-800 mr-1">
                            <a class="border-none
                             text-white
                             dark:text-zinc-200
                             hover:text-gray-900
                              hover:dark:text-gray-800" itemprop="mainEntityOfPage"
                                href="https://arxiv.org/abs/2405.16865">paper</a>
                        </span>

                        <span class="publication-link cursor-pointer
                             bg-sky-600 dark:bg-sky-700
                             hover:bg-sky-800
                             dark:hover:bg-sky-500
                             text-white
                             dark:text-zinc-200
                             dark:hover:text-gray-800
                             hover:text-gray-900
                             rounded-sm p-1 mr-1">
                            <button class="open-modal text-inherit"
                                data-target="#open-modal-grid-cell-conformal">cite</button>
                        </span>
                    </div>
                </div>
            </div>


            <div class="pub-wrapper w-full inline-flex flex-wrap items-center
                my-1.5 p-2.5 rounded bg-slate-100 dark:bg-slate-700 box-border
                leading-tight justify-around" id="latent-plan-transformer-planning-as-latent-variable-inference"
                itemscope itemtype="http://schema.org/ScholarlyArticle">
                <div class="pub-image basis-40 grow-0 shrink" itemprop="image" itemscope
                    itemtype="http://schema.org/ImageObject">
                    <img alt="Illustration of Latent Plan Transformer: Planning as Latent Variable Inference"
                        itemprop="url" src="img/LPT.png" class="w-full" />
                </div>
                <div class="publication grow shrink-2 basis-3/4 my-1.5 mx-2">
                    <br>
                    <b>
                        <a href="https://arxiv.org/abs/2402.04647">
                            <span itemprop="name">Latent Plan Transformer: Planning as Latent Variable Inference</span>
                        </a>
                    </b>
                    <meta itemprop="headline"
                        content="Latent Plan Transformer for Trajectory Abstraction: Planning as Latent Space Inference" />
                    <br>

                    <span itemprop="author" style="color: grey;">Deqian Kong*</span>,

                    <b><span itemprop="author">Dehong Xu*</span></b>,

                    <span itemprop="author" style="color: grey;">Minglu Zhao*</span>,

                    <span itemprop="author" style="color: grey;">Bo Pang</span>,

                    <span itemprop="author" style="color: grey;">Jianwen Xie</span>,

                    <span itemprop="author" style="color: grey;">Andrew Lizarraga</span>,

                    <span itemprop="author" style="color: grey;">Yuhao Huang</span>,

                    <span itemprop="author" style="color: grey;">Sirui Xie*</span>,

                    <span itemprop="author" style="color: grey;">Ying Nian Wu</span>

                    <div>
                        <!-- In  -->
                        <!-- <span itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                            <i itemprop="name">NeurIPS</i></span>, -->
                        <b><a href="https://nips.cc/Conferences/2024" target="_blank">NeurIPS 2024</a></b>

                        <!-- <meta itemprop="datePublished" content="2024">2024. -->
                    </div>
                    <div itemprop="description" class="pub-description text-sm my-1.5">
                        Decision-making via sequence modeling can be viewed as return-conditioned autoregressive
                        behavior cloning. Unaware of their own future behaviors, such models were thought to be
                        susceptible to drifting errors. Decision Transformer alleviates this issue by additionally
                        predicting the return-to-go labels. We propose an unsupervised solution, where a latent variable
                        is first inferred from a target return and then guides the policy throughout the episode,
                        functioning as a plan. Our model discovers improved decisions from suboptimal trajectories.
                    </div>
                    <div class="pub-link-wrapper mt-1.5 text-sm">
                        <span class="publication-link bg-sky-600
                             dark:bg-sky-700 rounded-sm p-1
                             dark:hover:bg-sky-500
                             hover:bg-sky-800 mr-1">
                            <a class="border-none
                             text-white
                             dark:text-zinc-200
                             hover:text-gray-900
                              hover:dark:text-gray-800" itemprop="mainEntityOfPage"
                                href="https://arxiv.org/abs/2402.04647">paper</a>
                        </span>
                        <!-- Uncomment this section if you have a project website -->

                        <span class="publication-link bg-sky-600
                             dark:bg-sky-700 rounded-sm p-1
                             dark:hover:bg-sky-500
                             hover:bg-sky-800 mr-1">
                            <a class="border-none
                             text-white
                             dark:text-zinc-200
                             hover:text-gray-900
                              hover:dark:text-gray-800" itemprop="mainEntityOfPage"
                                href="https://sites.google.com/view/latent-plan-transformer/home">website</a>
                        </span>

                        <span class="publication-link cursor-pointer
                             bg-sky-600 dark:bg-sky-700
                             hover:bg-sky-800
                             dark:hover:bg-sky-500
                             text-white
                             dark:text-zinc-200
                             dark:hover:text-gray-800
                             hover:text-gray-900
                             rounded-sm p-1 mr-1">
                            <button class="open-modal text-inherit"
                                data-target="#open-modal-latent-plan-transformer-planning-as-latent-variable-inference">cite</button>
                        </span>
                    </div>
                </div>
            </div>

            <div class="pub-wrapper w-full inline-flex flex-wrap items-center
                my-1.5 p-2.5 rounded bg-slate-100 dark:bg-slate-700 box-border
                leading-tight justify-around" id="aligning-large-language-models-via-fine-grained-supervision"
                itemscope itemtype="http://schema.org/ScholarlyArticle">
                <div class="pub-image basis-40 grow-0 shrink" itemprop="image" itemscope
                    itemtype="http://schema.org/ImageObject">
                    <img alt="Illustration of Aligning Large Language Models via Fine-grained Supervision"
                        itemprop="url" src="img/rlhf.png" class="w-full" />
                </div>
                <div class="publication grow shrink-2 basis-3/4 my-1.5 mx-2">
                    <br>
                    <b>
                        <a href="https://arxiv.org/abs/2402.04647">
                            <span itemprop="name">Aligning Large Language Models via Fine-grained Supervision</span>
                        </a>
                    </b>
                    <meta itemprop="headline"
                        content="Latent Plan Transformer for Trajectory Abstraction: Planning as Latent Space Inference" />
                    <br>

                    <b><span itemprop="author">Dehong Xu*</span></b>,

                    <span itemprop="author" style="color: grey;">Liang Qiu*</span>,

                    <span itemprop="author" style="color: grey;">Minseok Kim</span>,

                    <span itemprop="author" style="color: grey;">Faisal Ladhak</span>,

                    <span itemprop="author" style="color: grey;">Jaeyoung Do</span>,

                    <div>
                        <!-- In  -->
                        <!-- <span itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                            <i itemprop="name">NeurIPS</i></span>, -->
                        <b><a href="https://2024.aclweb.org/" target="_blank">ACL 2024</a></b>

                        <!-- <meta itemprop="datePublished" content="2024">2024. -->
                    </div>
                    <div itemprop="description" class="pub-description text-sm my-1.5">
                        We propose a method to enhance LLM alignment through fine-grained token-level supervision.
                        Specifically, we ask annotators to minimally edit less preferred responses within the standard
                        reward modeling dataset to make them more favorable, ensuring changes are made only where
                        necessary while retaining most of the original content. The refined dataset is used to train a
                        token-level reward model, which is then used for training our fine-grained token-level Proximal
                        Policy Optimization (PPO) model.
                    </div>
                    <div class="pub-link-wrapper mt-1.5 text-sm">
                        <span class="publication-link bg-sky-600
                             dark:bg-sky-700 rounded-sm p-1
                             dark:hover:bg-sky-500
                             hover:bg-sky-800 mr-1">
                            <a class="border-none
                             text-white
                             dark:text-zinc-200
                             hover:text-gray-900
                              hover:dark:text-gray-800" itemprop="mainEntityOfPage"
                                href="https://arxiv.org/abs/2406.02756">paper</a>
                        </span>
                        <!-- Uncomment this section if you have a project website -->

                        <span class="publication-link cursor-pointer
                             bg-sky-600 dark:bg-sky-700
                             hover:bg-sky-800
                             dark:hover:bg-sky-500
                             text-white
                             dark:text-zinc-200
                             dark:hover:text-gray-800
                             hover:text-gray-900
                             rounded-sm p-1 mr-1">
                            <button class="open-modal text-inherit"
                                data-target="#open-modal-aligning-large-language-models-via-fine-grained-supervision">cite</button>
                        </span>
                    </div>
                </div>
            </div>

            <div class="pub-wrapper w-full inline-flex flex-wrap items-center
                my-1.5 p-2.5 rounded bg-slate-100 dark:bg-slate-700 box-border
                leading-tight justify-around" id="spi" itemscope itemtype="http://schema.org/ScholarlyArticle">
                <div class="pub-image basis-40 grow-0 shrink" itemprop="image" itemscope
                    itemtype="http://schema.org/ImageObject">
                    <img alt="Illustration of Diverse and Faithful Knowledge-Grounded Dialogue Generation via Sequential Posterior Inference"
                        itemprop="url" src="img/SPI.png" class="w-full" />
                </div>
                <div class="publication grow shrink-2 basis-3/4 my-1.5 mx-2">
                    <br>
                    <b>
                        <a href="https://arxiv.org/abs/2306.01153">
                            <span itemprop="name">Diverse and Faithful Knowledge-Grounded Dialogue Generation via
                                Sequential Posterior Inference</span>
                        </a>
                    </b>
                    <meta itemprop="headline"
                        content="Latent Plan Transformer for Trajectory Abstraction: Planning as Latent Space Inference" />
                    <br>

                    <span itemprop="author" style="color: grey;">Yan Xu*,</span>

                    <span itemprop="author" style="color: grey;">Deqian Kong*,</span>

                    <b><span itemprop="author">Dehong Xu</span></b>,

                    <span itemprop="author" style="color: grey;">Ziwei Ji,</span>

                    <span itemprop="author" style="color: grey;">Bo Pang,</span>

                    <span itemprop="author" style="color: grey;">Pascale Fung,</span>

                    <span itemprop="author" style="color: grey;">Ying Nian Wu,</span>

                    <div>
                        <!-- In  -->
                        <!-- <span itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
                            <i itemprop="name">NeurIPS</i></span>, -->
                        <b><a href="https://icml.cc/Conferences/2023" target="_blank">ICML 2023</a></b>

                        <!-- <meta itemprop="datePublished" content="2024">2024. -->
                    </div>
                    <div itemprop="description" class="pub-description text-sm my-1.5">
                        In this paper, we present an end-to-end learning framework, termed Sequential Posterior
                        Inference (SPI), capable of selecting knowledge and generating dialogues by approximately
                        sampling from the posterior distribution. Unlike other methods, SPI does not require the
                        inference network or assume a simple geometry of the posterior distribution. This
                        straightforward and intuitive inference procedure of SPI directly queries the response
                        generation model, allowing for accurate knowledge selection and generation of faithful
                        responses.
                    </div>
                    <div class="pub-link-wrapper mt-1.5 text-sm">
                        <span class="publication-link bg-sky-600
                             dark:bg-sky-700 rounded-sm p-1
                             dark:hover:bg-sky-500
                             hover:bg-sky-800 mr-1">
                            <a class="border-none
                             text-white
                             dark:text-zinc-200
                             hover:text-gray-900
                              hover:dark:text-gray-800" itemprop="mainEntityOfPage"
                                href="https://arxiv.org/abs/2306.01153">paper</a>
                        </span>
                        <!-- Uncomment this section if you have a project website -->

                        <span class="publication-link cursor-pointer
                             bg-sky-600 dark:bg-sky-700
                             hover:bg-sky-800
                             dark:hover:bg-sky-500
                             text-white
                             dark:text-zinc-200
                             dark:hover:text-gray-800
                             hover:text-gray-900
                             rounded-sm p-1 mr-1">
                            <button class="open-modal text-inherit" data-target="#open-modal-spi">cite</button>
                        </span>
                    </div>
                </div>
            </div>

            <div id="#open-modal-ltm" class="modal-window bg-tp-black invisible fixed top-0 left-0
                right-0 bottom-0 transition-all pointer-events-none z-50">
                <div class="absolute top-1/2 left-1/2 p-8 bg-white
                    dark:bg-neutral-700
                    max-w-full
                    rounded-md max-w-4/5 -translate-x-1/2 -translate-y-1/2">
                    <button id="#close-modal-ltm"
                        title="Close" class="modal-close rounded-sm p-2">âœ•</button>
                    <h3>Cite <i>Scalable Language Models with Posterior Inference of Latent Thought Vectors</i></h3>
                    <button class="modal-copy-citation pr-2 pl-1 my-2 ml-2
                           bg-sky-600 dark:bg-sky-700 rounded-sm
                           text-white
                           dark:text-zinc-200
                           dark:hover:text-gray-800
                           hover:text-gray-900
                           hover:bg-sky-800
                           disabled:bg-neutral-500
                           hover:disabled:text-white
                           dark:hover:disabled:text-zinc-200
                           dark:disabled:bg-neutral-500
                           dark:hover:bg-sky-500" id="#copy-ltm">Copy to clipboard</button>
                    <pre class="bg-slate-100 dark:bg-slate-800"><code id="ltm">
@article{kong2025scalable,
    title={Scalable Language Models with Posterior Inference of Latent Thought Vectors},
    author={Kong, Deqian and Zhao, Minglu and Xu, Dehong and Pang, Bo and Wang, Shu and Honig, Edouardo and Si, Zhangzhang and Li, Chuan and Xie, Jianwen and Xie, Sirui and others},
    journal={arXiv preprint arXiv:2502.01567},
    year={2025}
}</code>
                    </pre>
                </div>
            </div>

            <div id="#open-modal-grid-cell-conformal" class="modal-window bg-tp-black invisible fixed top-0 left-0
                right-0 bottom-0 transition-all pointer-events-none z-50">
                <div class="absolute top-1/2 left-1/2 p-8 bg-white
                    dark:bg-neutral-700
                    max-w-full
                    rounded-md max-w-4/5 -translate-x-1/2 -translate-y-1/2">
                    <button id="#close-modal-grid-cell-conformal"
                        title="Close" class="modal-close rounded-sm p-2">âœ•</button>
                    <h3>Cite <i>An Investigation of Conformal Isometry Hypothesis for Grid Cells</i></h3>
                    <button class="modal-copy-citation pr-2 pl-1 my-2 ml-2
                           bg-sky-600 dark:bg-sky-700 rounded-sm
                           text-white
                           dark:text-zinc-200
                           dark:hover:text-gray-800
                           hover:text-gray-900
                           hover:bg-sky-800
                           disabled:bg-neutral-500
                           hover:disabled:text-white
                           dark:hover:disabled:text-zinc-200
                           dark:disabled:bg-neutral-500
                           dark:hover:bg-sky-500" id="#copy-grid-cell-conformal">Copy to clipboard</button>
                    <pre class="bg-slate-100 dark:bg-slate-800"><code id="grid-cell-conformal">
@article{xu2024investigation,
    title={An Investigation of Conformal Isometry Hypothesis for Grid Cells},
    author={Xu, Dehong and Gao, Ruiqi and Zhang, Wen-Hao and Wei, Xue-Xin and Wu, Ying Nian},
    journal={arXiv preprint arXiv:2405.16865},
    year={2024}
}</code>
                    </pre>
                </div>
            </div>
            
            <div id="#open-modal-latent-plan-transformer-planning-as-latent-variable-inference" class="modal-window bg-tp-black invisible fixed top-0 left-0
                right-0 bottom-0 transition-all pointer-events-none z-50">
                <div class="absolute top-1/2 left-1/2 p-8 bg-white
                    dark:bg-neutral-700
                    max-w-full
                    rounded-md max-w-4/5 -translate-x-1/2 -translate-y-1/2">
                    <button id="#close-modal-latent-plan-transformer-planning-as-latent-variable-inference"
                        title="Close" class="modal-close rounded-sm p-2">âœ•</button>
                    <h3>Cite <i>Latent Plan Transformer: Planning as Latent Variable Inference</i></h3>
                    <button class="modal-copy-citation pr-2 pl-1 my-2 ml-2
                           bg-sky-600 dark:bg-sky-700 rounded-sm
                           text-white
                           dark:text-zinc-200
                           dark:hover:text-gray-800
                           hover:text-gray-900
                           hover:bg-sky-800
                           disabled:bg-neutral-500
                           hover:disabled:text-white
                           dark:hover:disabled:text-zinc-200
                           dark:disabled:bg-neutral-500
                           dark:hover:bg-sky-500" id="#copy-latent-plan-transformer">Copy to clipboard</button>
                    <pre class="bg-slate-100 dark:bg-slate-800"><code id="latent-plan-transformer">
@article{kong2024latent,
    title={Latent Plan Transformer for Trajectory Abstraction: Planning as Latent Space Inference},
    author={Kong, Deqian and Xu, Dehong and Zhao, Minglu and Pang, Bo and Xie, Jianwen and Lizarraga, Andrew and Huang, Yuhao and Xie, Sirui and Wu, Ying Nian},
    journal={Advances in Neural Information Processing Systems},
    year={2024}
}</code>
                    </pre>
                </div>
            </div>

            <div id="#open-modal-aligning-large-language-models-via-fine-grained-supervision" class="modal-window bg-tp-black invisible fixed top-0 left-0
                right-0 bottom-0 transition-all pointer-events-none z-50">
                <div class="absolute top-1/2 left-1/2 p-8 bg-white
                    dark:bg-neutral-700
                    max-w-full
                    rounded-md max-w-4/5 -translate-x-1/2 -translate-y-1/2">
                    <button id="#close-modal-aligning-large-language-models-via-fine-grained-supervision" title="Close"
                        class="modal-close rounded-sm p-2">âœ•</button>
                    <h3>Cite <i>Aligning Large Language Models via Fine-grained Supervision</i></h3>
                    <button class="modal-copy-citation pr-2 pl-1 my-2 ml-2
                           bg-sky-600 dark:bg-sky-700 rounded-sm
                           text-white
                           dark:text-zinc-200
                           dark:hover:text-gray-800
                           hover:text-gray-900
                           hover:bg-sky-800
                           disabled:bg-neutral-500
                           hover:disabled:text-white
                           dark:hover:disabled:text-zinc-200
                           dark:disabled:bg-neutral-500
                           dark:hover:bg-sky-500" id="#copy-aligning-large-language-models">Copy to clipboard</button>
                    <pre class="bg-slate-100 dark:bg-slate-800"><code id="aligning-large-language-models">
@article{xu2024aligning,
    title={Aligning Large Language Models via Fine-grained Supervision},
    author={Xu, Dehong and Qiu, Liang and Kim, Minseok and Ladhak, Faisal and Do, Jaeyoung},
    journal={arXiv preprint arXiv:2406.02756},
    year={2024}
}</code>
                    </pre>
                </div>
            </div>

            <div id="#open-modal-spi" class="modal-window bg-tp-black invisible fixed top-0 left-0
                right-0 bottom-0 transition-all pointer-events-none z-50">
                <div class="absolute top-1/2 left-1/2 p-8 bg-white
                    dark:bg-neutral-700
                    max-w-full
                    rounded-md max-w-4/5 -translate-x-1/2 -translate-y-1/2">
                    <button id="#close-modal-spi" title="Close" class="modal-close rounded-sm p-2">âœ•</button>
                    <h3>Cite <i>Diverse and Faithful Knowledge-Grounded Dialogue Generation via Sequential Posterior
                            Inference</i></h3>
                    <button class="modal-copy-citation pr-2 pl-1 my-2 ml-2
                           bg-sky-600 dark:bg-sky-700 rounded-sm
                           text-white
                           dark:text-zinc-200
                           dark:hover:text-gray-800
                           hover:text-gray-900
                           hover:bg-sky-800
                           disabled:bg-neutral-500
                           hover:disabled:text-white
                           dark:hover:disabled:text-zinc-200
                           dark:disabled:bg-neutral-500
                           dark:hover:bg-sky-500" id="#copy-spi">Copy to clipboard</button>
                    <pre class="bg-slate-100 dark:bg-slate-800"><code id="spi">
@inproceedings{xu2023diverse,
    title={Diverse and faithful knowledge-grounded dialogue generation via sequential posterior inference},
    author={Xu, Yan and Kong, Deqian and Xu, Dehong and Ji, Ziwei and Pang, Bo and Fung, Pascale and Wu, Ying Nian},
    booktitle={International Conference on Machine Learning},
    pages={38518--38534},
    year={2023},
    organization={PMLR}
    }</code>
                    </pre>
                </div>
            </div>


        </section>
        <p>Â </p>

        <!-- Experience Section -->
        <section id="experience">
            <h2>Experience</h2>
            <div style="margin-bottom:25px;">
                <div class="pub-wrapper w-full inline-flex flex-wrap items-center
                my-1.5 p-2.5 rounded bg-white box-border
                leading-tight justify-around" id="spi" itemscope itemtype="http://schema.org/ScholarlyArticle">
                    <div class="pub-image basis-40 grow-0 shrink" itemprop="image" itemscope
                        itemtype="http://schema.org/ImageObject">
                        <img alt="Illustration of Diverse and Faithful Knowledge-Grounded Dialogue Generation via Sequential Posterior Inference"
                            itemprop="url" src="img/amazon-logo.jpg" class="w-full" />
                    </div>
                    <div class="publication grow shrink-2 basis-3/4 my-1.5 mx-2">
                        <span style="font-weight:bold; font-size:1.3em">Applied Scientist Intern</span>
                        <br> <span style="display:inline-block; margin-right:10px; font-size:1.15em"> Amazon Inc. -
                            Search M5
                            Team,
                            <em> 2024.06 - 2024.09</em></span> <br>
                    </div>
                </div>
                <!-- <span style="font-weight:bold; font-size:1.3em">Applied Scientist Intern</span>
                <br> <span style="display:inline-block; margin-right:10px; font-size:1.15em"> Amazon Inc. - Search M5
                    Team,
                    <em> 2024.06 - 2024.09</em></span> <br> -->
                <span style="font-weight:bold; font-size:1.em">Improving Instruction-following Capability of Multi-modal
                    Embedding Models</span><br>
                <strong style="color: darkblue;">(In submission to CVPR 2025)</strong>
                <ul>
                    <li>Developed a <strong style="color: darkblue;">multi-modal, decoder-only framework</strong> for
                        learning representations with
                        instruction-following capabilities.</li>
                    <li>Designed and implemented a <strong style="color: darkblue;">two-stage training
                            approach</strong>: a pre-training phase for modality
                        alignment, followed by instruction fine-tuning.</li>
                    <li>Our method achieved SoTA performance on multi-modal information retrieval benchmarks.</li>
                </ul>
            </div>
            <div style="margin-bottom:25px;">
                <div class="pub-wrapper w-full inline-flex flex-wrap items-center
                my-1.5 p-2.5 rounded bg-white box-border
                leading-tight justify-around" id="spi" itemscope itemtype="http://schema.org/ScholarlyArticle">
                    <div class="pub-image basis-40 grow-0 shrink" itemprop="image" itemscope
                        itemtype="http://schema.org/ImageObject">
                        <img alt="Illustration of Diverse and Faithful Knowledge-Grounded Dialogue Generation via Sequential Posterior Inference"
                            itemprop="url" src="img/amazon-logo.jpg" class="w-10 h-auto object-contain" />
                    </div>
                    <div class="publication grow shrink-2 basis-3/4 my-1.5 mx-2">
                        <span style="font-weight:bold; font-size:1.3em">Applied Scientist Intern</span>
                        <br> <span style="display:inline-block; margin-right:10px; font-size:1.15em"> Amazon Inc. -
                            Alexa
                            AGI
                            Team &
                            Rufus Team, <em> 2023.06 - 2023.10</em></span> <br>
                    </div>
                </div>

                <span style="font-weight:bold; font-size:1.em">Aligning Large Language Models via Fine-grained
                    Supervision and Token-level RLHF</span><br>
                <strong style="color: darkblue;">(Paper published in ACL 2024)</strong>
                <ul>
                    <li>Developed a <strong style="color: darkblue;">fine-grained data collection method</strong> for
                        reward training via minimal editing, which
                        pinpoints the exact output segments that affect user choices.</li>
                    <li>Proposed <strong style="color: darkblue;">token-level RLHF</strong> by training a token-level
                        reward
                        model with <strong style="color: darkblue;">fine-grained supervision</strong> and
                        incorporated it into PPO training.</li>
                    <li>Our method outperformed LLaMA2-chat-7B and achieved the SoTA performance on AlpacaFarm.</li>
                </ul>
            </div>
        </section>
        <p>Â </p>

        <!-- Service Section -->
        <section id="service">
            <h2>Professional Service</h2>
            <ul>
                <li><b>Conference Reviewer</b>: NeurIPS, ICLR, ICML, IJCAI, AISTATS, ACM MM</li>
                <li><b>Journal Reviewer</b>: TMLR, IEEE TNNLS, IEEE TIP, Stat</li>
            </ul>
        </section>
        <p>Â </p>

        <!-- Teaching Section -->
        <section id="teaching">
            <h2>Teaching</h2>
            <ul>
                <li><b>STATS 100A</b> Introduction to Probability</li>
                <li><b>STATS 102C</b> Introduction to Monte Carlo Methods</li>
                <li><b>STATS 202C</b> Monte Carlo Methods for Optimization</li>
                <li><b>STATS 231A</b> Pattern Recognition and Machine Learning</li>
                <li><b>STATS 231B</b> Methods of Machine Learning</li>
                <li><b>STATS 413</b> Machine Learning</li>
            </ul>
        </section>
        <p>Â </p>



    </main>
    <footer class="footer container h-10 text-center mt-1">
        <hr class="my-4">
        <ul class="pl-0 mt-1">

            <li class="ml-2 first:before:content-none before:content-['â€¢']
               inline-block list-none">
                <a class="ml-2 text-neutral-800
                dark:text-neutral-400 border-none" href="https://github.com/hugcis/hugo-astatine-theme">Code</a>
            </li>
            <li class="ml-2 first:before:content-none before:content-['â€¢']
                text-neutral-800 dark:text-neutral-400 inline-block list-none">
                <span class="ml-2">Â© Dehong Xu 2024</span>
            </li>
        </ul>
    </footer>
    <script>

        function toggleModal(win) {
            return ((event) => {
                if (event.target.id.startsWith("#open-modal") ||
                    event.target.id.startsWith("#close-modal") ||
                    event.target.classList.contains("open-modal")) {
                    event.stopPropagation();
                    win.classList.toggle("invisible");
                    win.classList.toggle("pointer-events-auto");
                    document.body.classList.toggle("pointer-events-none");
                }
            });
        }
        var list = document.getElementsByClassName("open-modal");
        for (let item of list) {
            var id = item.attributes["data-target"].textContent;
            var modWin = document.getElementById(id);
            var closeButton = document.getElementById(id.replace("open", "close"));

            item.addEventListener('click', toggleModal(modWin));
            closeButton.addEventListener('click', toggleModal(modWin));
            modWin.addEventListener('click', toggleModal(modWin));
        }
        var clipboardCopyButtons = document.getElementsByClassName("modal-copy-citation");
        for (let button of clipboardCopyButtons) {
            let citation_id = button.id.replace("#copy-", "");
            let citation_text = document.getElementById(citation_id);
            button.addEventListener('click', function (clicked) {
                return function () {
                    if (!clicked) {
                        var last = this.innerHTML;
                        navigator.clipboard
                            .writeText(citation_text.innerHTML)
                            .then(() => {
                                this.innerHTML = "Copied!";
                                this.disabled = true;
                            },
                                () => { this.innerHTML = "Error copying!"; });
                        clicked = true;
                        setTimeout(function () {
                            this.innerHTML = last;
                            this.disabled = false;
                            clicked = false;
                        }.bind(this), 1000);
                    }
                };
            }(false), this);
        }
    </script>

    <script async data-id="101469813" src="//static.getclicky.com/js"></script>


</body>

</html>